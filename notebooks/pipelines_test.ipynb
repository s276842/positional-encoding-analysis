{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from transformers import BartTokenizer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tokenizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.53MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0,    0,    0,    0,    0,  101, 3231, 6251,  102],\n",
       "        [ 101, 2023, 2003, 2019, 2130, 2936, 3231, 6251,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = AutoTokenizer.from_pretrained('bert-base-uncased', padding_side='left')\n",
    "# t.padding_side\n",
    "# t('a fhfhs fa sdfhas df asdhf',return_tensors='pt', padding=True)['input_ids']\n",
    "t([\n",
    "    'test sentence',\n",
    "    'this is an even longer test sentence'\n",
    "], return_tensors='pt', padding=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer(BartTokenizer):\n",
    "    _num_pads: int = 50\n",
    "\n",
    "    @property\n",
    "    def num_pads(self):\n",
    "        return self._num_pads\n",
    "\n",
    "    @num_pads.setter\n",
    "    def num_pads(self, value):\n",
    "        self._num_pads = value\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            padding_side='left', \n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        default_tokenization = super().__call__(\n",
    "            *args, \n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # input_ids => Tensor(batch size, input size)\n",
    "        input_ids = default_tokenization['input_ids']\n",
    "        attention_mask = default_tokenization['attention_mask']\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "\n",
    "        new_pads = torch.tensor([[super().pad_token_id] * self.num_pads] * batch_size)\n",
    "        new_pads_masks = torch.zeros((new_pads.shape[0], new_pads.shape[1]))\n",
    "\n",
    "        input_ids = torch.column_stack((new_pads, input_ids))\n",
    "        attention_mask = torch.column_stack((new_pads_masks, attention_mask))\n",
    "            \n",
    "        return {\n",
    "            'input_ids': input_ids, \n",
    "            'attention_mask':attention_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'CustomTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     0,    29, 36807,   281,  1437, 29831,  1236,\n",
       "           1236,  1236,  1236, 42898,   579,     2],\n",
       "         [    1,     1,     0,    29, 41587,   506,   449,   385,    29, 29831,\n",
       "           1236,  1437,  1236, 46155,   939,   257,  1717,  1020,  1021,  9060,\n",
       "            939,  1438,   939,   687,  5074,     2]]),\n",
       " 'attention_mask': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.]])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = CustomTokenizer.from_pretrained('facebook/bart-base')\n",
    "ct.num_pads = 2\n",
    "# ct('Harry Potter star Daniel Radcliffe turns 18 on monday . the young actor says he has')\n",
    "ct([\n",
    "    'sdfas  dj j j j j js s',\n",
    "    'sadjf k ds dj j  j io iu uio oiu iou ius sad'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     1,     1,     1,     1,     1,     1,     0,   102,   856,\n",
       "           298,   506, 15354, 18363,   579, 36807,  7333, 47942,    25, 16593,\n",
       "           506,     2],\n",
       "        [    0,  6629,  1906,   267,   298,   506,   579,  4779,   506, 36085,\n",
       "          1368,    29, 36807,  1368, 28045,   856, 36646,   506,  1021, 11000,\n",
       "           856,     2]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = BartTokenizer.from_pretrained('facebook/bart-base', padding_side='left')\n",
    "# t.padding_side\n",
    "# t('a fhfhs fa sdfhas df asdhf',return_tensors='pt', padding=True)['input_ids']\n",
    "t([\n",
    "    'a fhfhs fa sdfhas df asdhf',\n",
    "    'aksudjhf sldfkj hsdf hsd fhhf osi f'\n",
    "], return_tensors='pt', padding=True)['input_ids']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/nfs/home/marquez/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('cnn_dailymail', '3.0.0', split='train')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   574,  4524,     6,  1156,    36,  1251,    43,   480,  3268,\n",
      "         10997,   999,  3028,  7312, 20152,  3077,   899,     7,    10,   431,\n",
      "           984,   844,   153,  1358,  4006,     4,   134,   153,    43, 13016,\n",
      "            25,    37,  4072,   504,    15,   302,     6,    53,    37,  9838,\n",
      "             5,   418,   351,    75,  2471,    10,  8921,    15,   123,     4,\n",
      "          3028,  7312, 20152,    25,  3268, 10997,    11,    22, 29345, 10997,\n",
      "             8,     5,  9729,     9,     5,  5524,   113,   598,     5, 10208,\n",
      "             9, 20445,  6730,  1952,   198,     5,   232,     6,     5,   664,\n",
      "          2701,   161,    37,    34,   117,   708,     7,   856,  3961,  1334,\n",
      "            39,  1055,   409,    15,  1769,  1677,     6,  4076,     8,  6794,\n",
      "          1799,     4,    22,   100,   218,    75,   563,     7,    28,    65,\n",
      "             9,   167,    82,    54,     6,    25,  1010,    25,    51,  1004,\n",
      "           504,     6,  6017,   907,  1235,    10,  2232,  1612,   512,  2783,\n",
      "            50,   402,  1122,    60,    37,   174,    41,  2059, 33242,   656,\n",
      "            42,   353,     4,    22,   100,   218,    75,   206,    38,   581,\n",
      "            28,  1605, 31879,     4,    22,   133,   383,    38,   101,  2159,\n",
      "            32,   383,    14,   701,    59,   158,  2697,   480,  2799,     8,\n",
      "         32570,     8, 37206,    72,   497,   504,     6,  7312, 20152,    40,\n",
      "            28,   441,     7, 23104,    11,    10, 10297,     6,   907,    10,\n",
      "          4076,    11,    10,  8881,    50,   192,     5,  8444,   822,    22,\n",
      "         40534,   523,    35,  4657,  3082,    60,   855,   411,  2127,   874,\n",
      "            39,   346,    65,  1569,    15,     5,   987,  2233,   558,  5966,\n",
      "             4, 10574,     9,   141,    37,   581,  2458,    39, 10043,  4115,\n",
      "            32,   223, 18166,     4,   832,  2936,     8,   285,   661,    56,\n",
      "           117,  1129,    15,    39,   708,     4,    22,   100,   581,  2299,\n",
      "            33,   103,  2345,     9,   537,    60,    37,    26,    11,    41,\n",
      "          1194,     4,    22, 19204,  4146,     9,    47,    40,    28,  2600,\n",
      "            59,    24,    72,  7312, 20152,    18,  1107,    31,     5,    78,\n",
      "           292, 10997,  3541,    33,    57,   547,    11,    10,  2416,  1391,\n",
      "            61,    37,    34,    45,    57,   441,     7,  2842,     4,  2285,\n",
      "            39,  1197,  9444,     8, 33884,     6,     5,  2701,   161,    37,\n",
      "            16,  2396,    39,  1730, 10523,    15,     5,  1255,     4,    22,\n",
      "          4763,    32,   460,   546,     7,   224,   128, 30704,   999,  1411,\n",
      "           160,     5, 26717, 10076,    37,   174,  1865,    94,   353,     4,\n",
      "            22,  1708,    38,   860,   182,   543,    45,     7,   213,    14,\n",
      "           169,   142,    24,    74,    28,   350,  1365,    13,   106,    72,\n",
      "           832,   665,  9913,    25,     5,  2143, 32660,    11,    22, 29345,\n",
      "         10997,     8,     5,  9729,     9,     5,  5524,   113,    16,  3433,\n",
      "          2189,    15,   258,  2380,     9,     5,  5038,     8,    37,    40,\n",
      "           769, 22627,     5,   774,    11,     5,    94,    80,  3541,     4,\n",
      "          1437,  3075,    38,    12, 22026, 10679,   492,    69,  1551,     9,\n",
      "         10997,    18,   665,  9313,   479,   345,    16,   301,  1684, 10997,\n",
      "             6,   959,     4,    20,   928,   254,    34, 10571,    10,  1012,\n",
      "          1569,   373,    22,  2387,  5637,  2722,    60,    59,  2730, 19257,\n",
      "          2675, 11488, 20418,     8,    39,   979,     6,   528,    13,   800,\n",
      "           423,    42,    76,     4,    91,    40,    67,  2082,    11,    22,\n",
      "         17704,  8732,    60,    41,  2059,   822,    59,   237,  2786,    54,\n",
      "          5111,    41, 21297,  1580,     4,  3322,    42,    76,     6,    37,\n",
      "           156,    39,  1289,  2453,   816,    10, 20464,  7044,    11,  2155,\n",
      "           840, 16717,    18,    22, 28568,   687,    72,  2276,     6,    37,\n",
      "            16,  5378,  8988,    13,   190,  2789,   433,  7731,   122,    14,\n",
      "            37,    18,  7818,    41,  4194,    35,    22,   100,    95,   206,\n",
      "            38,   437,   164,     7,    28,    55,  2345,     9,  2105,   177,\n",
      "            60,    37,   174,  1201,     4,   381,    12,  6380,     7,    10,\n",
      "          1441,   479,  1894,  3010,  1201,     4,   404,   659,  1875,     4,\n",
      "           713,  1468,   189,    45,    28,  1027,     6,  2308,     6,  4599,\n",
      "             6,    50,  3802,     4,     2]])\n",
      "tensor([], size=(0, 565), dtype=torch.int64)\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1368937/2623439699.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.concat((pads, torch.tensor(shifted_ids)))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m summarizer \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39msummarization\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfacebook/bart-base\u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m=\u001b[39mct, framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m summarizer(ds[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39marticle\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/positional-encoding-analysis/.venv/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:265\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    242\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/positional-encoding-analysis/.venv/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:165\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    167\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    168\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    169\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    170\u001b[0m     ):\n\u001b[1;32m    171\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/positional-encoding-analysis/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1119\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1112\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1113\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         )\n\u001b[1;32m   1117\u001b[0m     )\n\u001b[1;32m   1118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/positional-encoding-analysis/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1125\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m-> 1125\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpreprocess_params)\n\u001b[1;32m   1126\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[1;32m   1127\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n",
      "File \u001b[0;32m~/positional-encoding-analysis/.venv/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:175\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.preprocess\u001b[0;34m(self, inputs, truncation, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(\u001b[39mself\u001b[39m, inputs, truncation\u001b[39m=\u001b[39mTruncationStrategy\u001b[39m.\u001b[39mDO_NOT_TRUNCATE, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 175\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_and_tokenize(inputs, truncation\u001b[39m=\u001b[39;49mtruncation, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/positional-encoding-analysis/.venv/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:130\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._parse_and_tokenize\u001b[0;34m(self, truncation, *args)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    128\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `args[0]`: \u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m have the wrong format. The should be either of type `str` or type `list`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m     )\n\u001b[0;32m--> 130\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(\u001b[39m*\u001b[39;49margs, padding\u001b[39m=\u001b[39;49mpadding, truncation\u001b[39m=\u001b[39;49mtruncation, return_tensors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframework)\n\u001b[1;32m    131\u001b[0m \u001b[39m# This is produced by tokenizers but is an invalid generate kwargs\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inputs:\n",
      "Cell \u001b[0;32mIn[38], line 25\u001b[0m, in \u001b[0;36mCustomTokenizer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(shifted_ids)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(pads)\n\u001b[0;32m---> 25\u001b[0m input_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mconcat((pads, torch\u001b[39m.\u001b[39;49mtensor(shifted_ids)))\n\u001b[1;32m     26\u001b[0m \u001b[39m# print(input_ids)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m1\u001b[39m, input_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-base\", tokenizer=ct, framework=\"pt\")\n",
    "summarizer(ds[0]['article'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
